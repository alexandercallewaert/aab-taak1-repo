---
title: "Assignment 1 - Report"
author: "Group 29"
date: "4/12/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/github/aab-taak1-repo")
rm(list=ls())
```

# 1. Introduction: Loading Data

```{r}
library(tidyverse)     ## install.packages("tidyverse")
library(readr)
library(dplyr)
library(knitr)

library(mice)         ## to impute missing values 
library(randomForest)
```

```{r, message=FALSE, warning=FALSE}
## read train data csv. Note the readr:: prefix identifies which package it's in
# TRAIN <- readr::read_csv2("data/train.csv") contains only 78 original variables
load("data/train.RData") # contains the date values in separated columns 
attach(train)
train_origineel <- train

load("data/test.RData")
test_origineel <- test
```

"train.RData" contains the date variables in different columns and the variables are factorised and made numeric (where TRAIN does not). This dataset is obtained with the "MAKE_2_DATASETS.R" file (see Additional code: cleaning datasets). The test data is also modified in this R script. It's easy to load both datasets into the R environment with the load command.  

Now we're going to look at the missing values for each variable. 

# 2. Exploratory Analysis & Preprocessing
## A. Exploratory Analysis 

Understanding features

### Bar plots
```{r}
attach(train)
ggplot(data = train) +
  geom_bar(mapping = aes(x = fraud))
## Massive class imbalance

ggplot(data = train) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)
ggplot(data = train) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 50)
## There seem to be a distribution of claim amounts around 1000 and outliers located above 15 000

ggplot(data = train) +
  geom_bar(mapping = aes(x = claim_cause))
## Dominant cause of claim registration is traffic_accident
```

### Facets & Frequency polygons

```{r}
ggplot(data = train) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)+
  facet_wrap(~fraud)

ggplot(data = train, mapping = aes(x = claim_amount, colour = fraud)) +
  geom_freqpoly(binwidth = 500)
## It seems like there is an equal distribution no matter whether fraud or not
## Trying to zoom in on fraud == "Y" case using most_fraudulent data frame

ggplot(data = most_fraudulent) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)
ggplot(data = most_fraudulent) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 100)
## Generally speaking, same distribituion; but also intermediate cases between 1000 and 15000

ggplot(data = most_fraudulent, mapping = aes(x = claim_amount, colour = claim_cause)) +
  geom_freqpoly(binwidth = 400)
```

### Covariation

```{r}
ggplot(data = most_fraudulent, mapping = aes(x = claim_num_vehicles, y = claim_amount)) + 
  geom_boxplot(mapping = aes(group = cut_width(claim_num_vehicles, 1)))
## This is interesting!
## For fraudulent cases, we see that there is some exceptionally high claim amounts when one vehicle is involved
```

### Correlation

## B. Preprocessing  

### Cleaning data

```{r Kolommen verwijderen}
## nutteloze kolommen weg, maar claim_ID bijhouden, want later nog nodig!! Deze claim_ids staan in een belangrijke volgorde! 

claim_ID_train <- train[, 1]
claim_ID_test <- test[,1]

train <- train %>%
  select(!(claim_id))

train <- train %>%
  select(!(claim_amount))
```

Rijen: we verwijderen rijen waar geldt dat vehicle_id niet overeenkomt met claim_vehicle_id. Deze rijen die verwijderd worden, worden in een apart dataset "b_train/test" gestoken, om achteraf apart te behandelen met een model die enkel deze cases zal behandelen en zal getraind worden op basis van de train gevallen waar dit ook het geval is! 

```{r Rijen verwijderen}
## Origineel (gebruikt voor eerste 6 attempts)

train <- train %>% 
  filter(as.character(train$driver_vehicle_id) == as.character(train$claim_vehicle_id))

## Train -> splitsen in twee datasets! 
A_train <- train
B_train <- train
train_numbers <- c(1:nrow(train))

A_train_filter <- as.vector(which(as.character(train$driver_vehicle_id) ==
                                    as.character(train$claim_vehicle_id)))
B_train_filter <- train_numbers[-A_train_filter]
length(A_train_filter) + length(B_train_filter)

A_train <- train[A_train_filter, ] # contains only values where filter is applied 
B_train <- train[B_train_filter,]
nrow(A_train) + nrow(B_train) == nrow(train) # goed gesplitst! 

## Train -> splitsen in twee datasets! 
A_test <- test
B_test <- test
test_numbers <- c(1:nrow(test))

A_test_filter <- as.vector(which(as.character(test$driver_vehicle_id) ==
                                   as.character(test$claim_vehicle_id)))
B_test_filter <- test_numbers[-A_test_filter]

A_test <- test[test_filter, ] # contains only values where filter is applied 
B_test <- test[-test_filter,]
nrow(A_test) + nrow(B_test) == nrow(test) 
```

### How many missing values? 

Let's start by seeing how much missing data there is per feature. Usually a safe maximum threshold is 5% of the total for large datasets. If missing data for a certain feature or sample is more than 5% then we probably should leave that feature or sample out. We therefore check for features (columns) and samples (rows) where more than 5% of the data is missing using a simple function

```{r missing values}
miss <- function(x) # to compute NA% of variables 
  {sum(is.na(x))/length(x)*100}

compute_NA_matrix <- function(x)  # matrix of NA%
  {y <- as.matrix(round(apply(x, 2, miss), 6), dimnames = list(c(colnames(x)), c("NA")))
  colnames(y) <- c("Percentage NA")
  return(y)}

NA_variables_threshold <- function(dataset, threshold) # list with variables with NA% > threshold
  {NA_list <- c()
  NA_matrix <- compute_NA_matrix(dataset)
  variables <- rownames(NA_matrix)
  
  for (i in 1:nrow(NA_matrix))
  {newElement <- variables[i]
  if  (NA_matrix[i,1] <= threshold) 
      {NA_list <- c(NA_list, newElement)}}
  return(NA_list)}

compute_NA_thresholdmatrix <- function(dataset, threshold) # matrix with variables with NA% > threshold
  {dataset <- dataset %>% select(all_of(NA_variables_threshold(dataset, threshold)))
  return(compute_NA_matrix(dataset))}

compute_imp_variables <- function(dataset, threshold) # variables that have to be imputed! 
  {NA_variables <- NA_variables_threshold(dataset, threshold) 
  dataset <- dataset %>% select(all_of(NA_variables))
  
  NA_matrix <- compute_NA_matrix(dataset)
  to_impute_variables <- (NA_matrix[,1] != 0)
  NA_matrix <- data.frame(NA_matrix[to_impute_variables,])
  return(NA_matrix)}

compute_average_NA <- function(dataset)
  {x <- sum(compute_NA_matrix(dataset))/length(dataset)
  return(x)}

train <- train %>% 
  select(all_of(NA_variables_threshold(train, 20)))

compute_NA_matrix(train_origineel)      # Geeft oorspronkelijke % of missing values for all variables
compute_average_NA(train_origineel)     # 36% missing values! 

compute_NA_matrix(A_train)
compute_average_NA(A_train)             # 34.4% missing values!

compute_NA_matrix(B_train)
compute_average_NA(B_train)             # 49% missing values!


compute_NA_matrix(test_origineel)
compute_average_NA(test_origineel)      # 37% missing values 

compute_NA_matrix(A_test)
compute_average_NA(A_test)             # 34.2% missing values!

compute_NA_matrix(B_test)
compute_average_NA(B_test)             # 49% missing values!

compute_NA_thresholdmatrix(A_train, 20) # Geeft % of missing values for variables for which threshold hold
compute_NA_thresholdmatrix(A_test, 20)

compute_NA_thresholdmatrix(B_train, 20) # Geeft % of missing values for variables for which threshold hold
compute_NA_thresholdmatrix(B_test, 20)

compute_imp_variables(train, 20)        # Geeft een matrix van variabelen die ge√Ømputeerd moeten worden
compute_imp_variables(test, 20)         # volgens een bepaalde threshold! 
```

This way we select all variables for which the threshold is bigger than the percentage of missing values. We put the variables for which this is true in a list and with this list we select the columns of the train dataset to do the predictive learning. 

```{r selecting variables}
#### Origineel: gebruikt voor eerste 6 attempts #### 

all_variables <- NA_variables_threshold(train, 20) # alle variabelen die we opnemen in het model volgens onze train data en threshold. We houden enkel de variabelen over die we voor de train data gebruiken en gebruiken ook enkel deze voor onze test data! Wel opletten, all_variables bevat ook nog de kolom met "fraud", deze kolom bestaat niet voor test data, daarom all_variables[-1] 
all_variables <- all_variables[-1]

test <- test %>% 
  select(all_of(all_variables[-1]))
```


```{r opsplitsen van dataset}
#### Gebruikt waar we iedere dataset opsplitsen in twee datasets #### 
A_train <- A_train %>% 
  select(all_of(NA_variables_threshold(A_train, 20)))

B_train <- B_train %>%
  select(all_of(NA_variables_threshold(A_train, 20))) # zelfde variabelen gebruiken als A_train..., 
# kunnen we ook eens veranderen (naar B_train) en zien of het betere resultaten geeft. 

A_imp_variables <- rownames(compute_imp_variables(A_train, 20))
B_imp_variables <- rownames(compute_imp_variables(A_train, 20))
A_all_variables <- NA_variables_threshold(A_train, 20) # alle variabelen die we opnemen in model! 

A_test <- A_test %>% 
  select(all_of(A_all_variables[-1]))

B_test <- B_test %>%
  select(all_of(A_all_variables[-1]))

compute_NA_matrix(A_test)
compute_NA_matrix(B_test) # We gaan enkel met dezelfde variabelen werken in test als in train! 

most_fraudulent <- train_origineel %>% 
  filter(fraud == "Y") %>% 
  arrange(desc(claim_amount))
sum(most_fraudulent[1:100, "claim_amount"])
```

Even kijken wat som van 100 grootste fraudulente claims is om een idee te hebben van de grootte-orde. 

### Imputing 

Zowel de train set als de originele test set moeten behandeld worden voor de missing values. Bij de test set zal onze random forest anders ook NA kunnen voorspellen (denk ik momenteel omdat er NA values aanwezig waren bij predict). 

```{r}
compute_NA_matrix(A_train) # alle variabelen met hun %, ook die 0% zijn
compute_NA_matrix(B_train) # zie later hoe we dit gaan gebruiken! 

compute_imp_variables(A_train, 20) # zonder de 0%, dit zijn dus alle variabelen die ge√Ømputeerd moeten worden
```

Now, the imputing. You have a lot of different packages to do this! 

#### Which variables to impute? 

```{r}
library(mice)         ## to impute missing values 

imputing_var_train <- rownames(compute_imp_variables(train, 20))
imputing_var_test <- rownames(compute_imp_variables(test, 20))

NA_matrix_train <- compute_NA_matrix(train) 
NA_matrix_TEST <- compute_NA_matrix(test)

variables_train <- rownames(NA_matrix_train)
variables_test <- rownames(NA_matrix_TEST)

## Look at the variables with missing values 

row_imp_var_train  <- which(NA_matrix_train[,1] != 0) # list of variables with missing values
name_imp_var_train <- names(row_imp_var_train)     # name of variable in train for which we impute
vctr_imp_var_train <- as.vector(row_imp_var_train) # number original column in train for which we impute 
imp_var_train <- cbind(name_imp_var_train, vctr_imp_var_train)
head(imp_var_train)

row_imp_var_test  <- which(NA_matrix_TEST[,1] != 0) # list of variables with missing values
name_imp_var_test <- names(row_imp_var_test)     # name of variable in test for which we impute
vctr_imp_var_test <- as.vector(row_imp_var_test) # number original column in test for which we impute 
imp_var_test <- cbind(name_imp_var_test, vctr_imp_var_test)
head(imp_var_test)
```

#### Imputing the train & test data

We gaan beginnen met 2 methodes om te imputeren! Imputation at level-2 by Predictive mean matching (any), duurt lang om te berekenen, daarom dat ik de ingevulde datasets (zie verder: train1, train2, test1, test2) als files op sla, zodat je ze snel opnieuw kunt laden indien nodig, wel opletten als je ze verandert in je code en je oude files blijft gebruiken! ... 

```{r}
library(mice)
methods(mice)

# Heel deze chunk laden duurt makkelijk 15 uur. 's Avonds om 23u laten starten, om 9u volgende ochtend was test_impute1 volledig afgerond, maar test_impute2 nog maar net klaar met eerste iteratie (maxit = 10). Best deze chunk niet laden, maar gewoon de datasets op het einde van volgende chunk inladen en daar mee werken.
train_impute1 <- mice(train[, vctr_imp_var_train], m = 1, 
                      method = "pmm", 
                      maxit = 10) 

train_impute2 <- mice(train[, vctr_imp_var_train], m = 1, 
                      method = "rf", 
                      maxit = 10) 
# Duurt zeer lang, maar nog langer voor de testset! 

test_impute1 <- mice(test[, vctr_imp_var_test], m = 1, 
                      method = "pmm", 
                      maxit = 10) 

test_impute2 <- mice(test[, vctr_imp_var_test], m = 1, 
                      method = "rf", 
                      maxit = 10) 

# Zodra je dit geladen hebt, duurde enkele uren bij mij, deze ge√Ømputeerde waarden invullen in de dataset en vervolgens de datasets opslaan! 
```

#### Completing the datasets (train & test)

```{r}
complete_data <- function(dataset, impute, imputing_var, name_imp_var, vctr_imp_var) 
  # complete data with imputed values
  {
  DATASET <- dataset
  
  for (i in 1:nrow(imputing_var))
    {
      imp_variable <- data.frame(impute$imp[name_imp_var[i]])
      matrix_imp_variable <- cbind(rownames(imp_variable), imp_variable)
    
    for (j in 1:nrow(matrix_imp_variable)) # loop for every value of one imputed variable
      {
        ID <- matrix_imp_variable[j,1]   # number of observation in train dataset 
        VALUE <- matrix_imp_variable[j,2] # imputed value
      
        DATASET[ID, vctr_imp_var[i]] <- VALUE} # assign value to [obs. n¬∞, col imputed var]
      }
  return(DATASET)}

#### Zonder verschil in filter van vehicle_id: 1 model voor alle cases! #### 

train1 <- complete_data(train, train_impute1, imp_var_train, name_imp_var_train, vctr_imp_var_train)
compute_NA_matrix(train1)

train2 <- complete_data(train, train_impute2, imp_var_train, name_imp_var_train, vctr_imp_var_train)
compute_NA_matrix(train2)

test1 <- complete_data(test, test_impute1, imp_var_test, name_imp_var_test, vctr_imp_var_test)
compute_NA_matrix(test1)

## Fout, claim_vehicle_ID is hier helemaal verkeerd ge√Ømputeerd, geen idee hoet dit komt...
delete <- which(colnames(test1) == "claim_vehicle_id")
test1 <- test1[,-delete]
compute_NA_matrix(test1)

test2 <- complete_data(test, test_impute2, imp_var_test, name_imp_var_test, vctr_imp_var_test)
compute_NA_matrix(test2)
delete <- which(colnames(test2) == "claim_vehicle_id")
test2 <- test2[,-delete]
compute_NA_matrix(test2)

delete <- which(colnames(train1) == "claim_vehicle_id")
train1 <- train1[,-delete]

delete <- which(colnames(train2) == "claim_vehicle_id")
train2 <- train2[,-delete]

save(train1, file = "train1.RData")
save(train2, file = "train2.RData")
save(test1, file = "test1.RData")
save(test2, file = "test2.RData")

load("train1.RData") 
load("train2.RData")
load("test1.RData")
load("test2.RData")
```

Nu moeten we wel nog de cases imputeren waar we de vorige keer deze verwijderd hebben! 

```{r}
#### Met verschil voor vehicle_id filter, we maken zo twee modellen! 

B_train_impute1 <- mice(B_train[, vctr_imp_var_train], m = 1, 
                      method = "pmm", 
                      maxit = 10) # Dit gaat zeer snel

B_train_impute2 <- mice(B_train[, vctr_imp_var_train], m = 1, 
                      method = "rf", 
                      maxit = 10) 

### A = No cases where vehicle_id != vehicle_id, B = Only cases where vehicle_id != vehicle_id
### (method 1: PMM, method 2: RF) 
A_train1 <- train1  # PMM, only cases where columns are the same! 
B_train1 <- complete_data(B_train, B_train_impute1, imp_var_train, name_imp_var_train, vctr_imp_var_train)

A_test1 <- test1[A_test_filter,]
B_test1 <- test1[B_test_filter,]


A_train2 <- train2 
B_train2 <- complete_data(B_train, B_train_impute2, imp_var_train, name_imp_var_train, vctr_imp_var_train)

A_test2 <- test2[A_test_filter,]
B_test2 <- test2[B_test_filter,]


compute_NA_matrix(A_train1)
compute_NA_matrix(B_train1)     # claim_vehicle_power, driver_vehicle_id, claim_vehicle_id
compute_NA_matrix(A_test1)
compute_NA_matrix(B_test1)

compute_NA_matrix(A_train2)
compute_NA_matrix(B_train2)     # claim_vehicle_power, driver_vehicle_id, claim_vehicle_id
compute_NA_matrix(A_test2)
compute_NA_matrix(B_test2)
```

Weer hoge NA's voor 3 variabelen bij de B_dataset (waar vehicle_id != claim_vehicle_id), we gaan dus voor elke B dataset deze variabelen verwijderen. Voor de A_dataset maakt dit niet veel uit, aangezien er een apart model komt voor A en apart model voor B. 

```{r}
delete <- which(colnames(B_train1) %in% c("claim_vehicle_id", "claim_vehicle_power", "driver_vehicle_id"))
B_train1 <- B_train1[,-delete]
B_train2 <- B_train2[,-delete]

compute_NA_matrix(B_train1)
compute_NA_matrix(B_train2)

delete <- which(colnames(B_test1) %in% c("claim_vehicle_id", "claim_vehicle_power", "driver_vehicle_id"))
B_test1 <- B_test1[,-delete]
B_test2 <- B_test2[,-delete]

compute_NA_matrix(B_test1)
compute_NA_matrix(B_test2)

save(A_train1, file = "data/A_train1.RData")
save(A_train2, file = "data/A_train2.RData")
save(A_test1, file = "data/A_test1.RData")
save(A_test2, file = "data/A_test2.RData")

save(B_train1, file = "data/B_train1.RData")
save(B_train2, file = "data/B_train2.RData")
save(B_test1, file = "data/B_test1.RData")
save(B_test2, file = "data/B_test2.RData")
```


# 3. Construction of the learning model

Error: random forest kan niet werken met factoren waarvan er meer dan 53 levels zijn, dit is een probleem voor: "policy_coverage_type"
```{r}
delete_categorical <- function(x)
  {
    variables <- colnames(x) # names of columns 
    FA_list <- c()
    NA_list <- variables           
    DATASET <- x 

    for (i in 1:ncol(x))     # add those categorical variables to FA_list
      {
        newElement <- variables[i]
        if (class(x[[i]]) == "factor" && nlevels(x[[i]]) > 53) 
            {FA_list <- c(FA_list, newElement)}
      }
    
    for (i in 1:length(FA_list)) # delete elements from NA_list which are in FA_list
      {
        element <- FA_list[i]
        NA_list <- NA_list[NA_list != element]
      }
    
    DATASET <- x %>% select(all_of(NA_list))
    return(DATASET)
  }

train1 <- delete_categorical(train1)
train2 <- delete_categorical(train2)

test1 <- delete_categorical(test1)
test2 <- delete_categorical(test2)
```

Random forest learning model.

```{r Split Data}
# First we split the train data in test and training! Volgens mij niet nodig voor Random Forest, is gewoon enkel nodig om accuracy te meten denk ik!...

prop_train <- 0.8 # proportion of train and test set! 
prop_test <- 1-prop_train 

training_size1 <- floor((prop_train)*nrow(train))
training_size2 <- floor((prop_train)*nrow(train))
set.seed(122000)
# set.seed(34), naargelang deze waarde verschilt kies sample andere random getallen! 

train_index1 <- sample(seq_len(nrow(train)), size = training_size1)
train_index2 <- sample(seq_len(nrow(train)), size = training_size2)

# Train dataset from train data
train1_train      <- train1[train_index1,]
train1_trainLabel <- train1_train[,1]
train2_train      <- train2[train_index2,]
train2_trainLabel <- train2_train[,1]

# Test datasets from train data!!
train1_test       <- train1[-train_index1,]
train1_testLabel  <- train1_test[,1]
train2_test       <- train2[-train_index2,]
train2_testLabel  <- train2_test[,1]
```

```{r}
## Random forest op de train set van de train data! Hier kan je beginnen spelen en zien wat het beste resultaat oplevert...

accuracy_predicted <- function(RF_model, test_set)
  {
  predicted <- predict(RF_model, test_set)
  tab <- table(test_set$fraud, predicted)
  err <- round((1-sum(diag(tab1))/sum(tab1)), 4)
  tab <- cbind(tab, err)
  colnames(tab) <- c("NO", "YES", "ACCURACY")
  return(tab)  
}

create_csv <- function(RF_model, test_data)
  {
  predicted_values <- predict(RF_model, newdata = test_data, type = "prob")
  probabilities <- predicted_values[,2]
  
  csv_file <- cbind(claim_ID_test, probabilities)
  return(csv_file)
  }
```

### Building the models! 

Attempt 1... Score = 288629.61, AUC = 0.68532983
```{r}
RFmodel1 <- randomForest(
  train1_train$fraud~.,
  data = train1_train,
  ntree = 100)                  # Random Forest model of entry 1 online! 

accuracy_predicted(RFmodel1, train1_test)
csv_entry1 <- create_csv(RFmodel1, test1)
write.csv(csv_entry1, "CSV_entry1.csv", row.names = FALSE)
```

```{r}
RFmodel <- randomForest(
  train2_train$fraud~.,
  data = train2_train,
  ntree = 100)

accuracy_predicted(RFmodel, train2_test)
csv_entry <- create_csv(RFmodel, test2)
write.csv(csv_entry, "CSV_entry.csv", row.names = FALSE)
```

Attempt 2. No splitting for test and train set and more numbers of trees in random forest learning model! Score = 321323.1, AUC = 0.72061521
```{r model 2}
RFmodel <- randomForest(
  train1$fraud~.,
  data = train1,
  ntree = 1000)

csv_entry <- create_csv(RFmodel, test1)
write.csv(csv_entry, "CSV_entry2.csv", row.names = FALSE) # entry 2 online!
```

Attempt 3, same as attempt 2, but now we use test2 of the imputed test set... 
Score = 317565.2 and AUC = 0.71105264
```{r model 3}
RFmodel <- randomForest(
  train1$fraud~.,
  data = train1,
  ntree = 1000)

csv_entry <- create_csv(RFmodel, test2)
write.csv(csv_entry, "CSV_entry3.csv", row.names = FALSE) # entry 2 online!
```

Attempt 4, use train2 to learn random forest model! Score = 328096.4 and AUC 0.71132037
```{r model 4}
RFmodel <- randomForest(
  train2$fraud~.,
  data = train2,
  ntree = 500)

csv_entry <- create_csv(RFmodel, test2)
write.csv(csv_entry, "CSV_entry4.csv", row.names = FALSE) # entry 4 online!
```

Attempt 5, more number of trees for the previous model and other test set! Score = 321323.1
and AUC = 0.71659454
```{r model 5}
RFmodel <- randomForest(
  train2$fraud~.,
  data = train2,
  ntree = 1000)

csv_entry <- create_csv(RFmodel, test1)
write.csv(csv_entry, "CSV_entry5.csv", row.names = FALSE)
```

Attempt 6, score = 325755.16 and AUC = 0.71442148

```{r model 6}
RFmodel <- randomForest(
  train2$fraud~.,
  data = train2,
  ntree = 1000)

csv_entry <- create_csv(RFmodel, test2)
write.csv(csv_entry, "CSV_entry6.csv", row.names = FALSE)
```

Attempts where we split each original dataset in two datasets! 

```{r}
delete_categorical <- function(x)
  {
    variables <- colnames(x) # names of columns 
    FA_list <- c()
    NA_list <- variables           
    DATASET <- x 

    for (i in 1:ncol(x))     # add those categorical variables to FA_list
      {
        newElement <- variables[i]
        if (class(x[[i]]) == "factor" && nlevels(x[[i]]) > 53) 
            {FA_list <- c(FA_list, newElement)}
      }
    
    for (i in 1:length(FA_list)) # delete elements from NA_list which are in FA_list
      {
        element <- FA_list[i]
        NA_list <- NA_list[NA_list != element]
      }
    
    DATASET <- x %>% select(all_of(NA_list))
    return(DATASET)
  }

A_train1 <- delete_categorical(A_train1)
A_train2 <- delete_categorical(A_train2)

A_test1 <- delete_categorical(A_test1)
A_test2 <- delete_categorical(A_test2)

B_train1 <- delete_categorical(B_train1)
B_train2 <- delete_categorical(B_train2)

B_test1 <- delete_categorical(B_test1)
B_test2 <- delete_categorical(B_test2)
```


#### Random Forest model

```{r model 7}
library(randomForest)
A_RFmodel1 <- randomForest(
  A_train1$fraud~.,
  data = A_train1,
  ntree = 500)

CSV <- matrix(nrow = nrow(test_origineel), ncol = 2)
CSV <- data.frame(CSV)
predicted_values <- predict(A_RFmodel1, newdata = A_test1, type = "vote")
probabilities <- data.frame(predicted_values[,2])

for (i in 1:length(A_test_filter))
  {
  x <- A_test_filter[i]
  claim_ID <- claim_ID_test[x,]
  probability <- probabilities[i,1]
  
  CSV[i,1] <- claim_ID
  CSV[i,2] <- probability
  }


B_RFmodel1 <- randomForest(
  B_train2$fraud~.,
  data = B_train1,
  ntree=500)

predicted_values <- predict(B_RFmodel1, newdata = B_test1, type = "vote")
probabilities <- data.frame(predicted_values[,2])

for (i in 1:length(B_test_filter))
  {
  x <- B_test_filter[i]
  claim_ID <- claim_ID_test[x,]
  probability <- probabilities[i,1]
  
  i <- i+24330
  
  CSV[i,1] <- claim_ID
  CSV[i,2] <- probability
  }

compute_NA_matrix(CSV)
write.csv(testje, "CSV_entry7.csv", row.names = FALSE) 
```
Dit model geeft een score van: 308777.54 en AUC van 0.75288442. 


```{r model 8}
library(randomForest)
A_RFmodel2 <- randomForest(
  A_train2$fraud~.,
  data = A_train2,
  ntree = 1000)

CSV <- matrix(nrow = nrow(test_origineel), ncol = 2)
CSV <- data.frame(CSV)
predicted_values <- predict(A_RFmodel2, newdata = A_test2, type = "vote")
probabilities <- data.frame(predicted_values[,2])

for (i in 1:length(B_test_filter))
  {
  x <- A_test_filter[i]
  claim_ID <- claim_ID_test[x,]
  probability <- probabilities[i,1]
  
  CSV[i,1] <- claim_ID
  CSV[i,2] <- probability
  }


B_RFmodel2 <- randomForest(
  B_train2$fraud~.,
  data = B_train2,
  ntree=1000)

predicted_values <- predict(B_RFmodel2, newdata = B_test2, type = "vote")
probabilities <- data.frame(predicted_values[,2])

for (i in 1:length(B_test_filter))
  {
  x <- B_test_filter[i]
  claim_ID <- claim_ID_test[x,]
  probability <- probabilities[i,1]
  
  i <- i+24330
  
  CSV[i,1] <- claim_ID
  CSV[i,2] <- probability
  }

compute_NA_matrix(CSV)
write.csv(CSV, "CSV_entry8.csv", row.names = FALSE) 
```
Dit model geeft een score van: 325755.16, en AUC van = 0.72011965

# 4. Improvements
# 5. Additional Code

## Cleaning datasets 
```{r}
library(lubridate)  # to convert to date
library(zoo)        # to convert to date
library(tidyr)      # to separate date columns 
library(tidyverse)  # to separate date columns 

train <- read_delim("train.csv", ";", escape_double = FALSE, trim_ws = TRUE)
test <- read_delim("test.csv", ";", escape_double = FALSE, trim_ws = TRUE)

#############
### TRAIN ###
#############

attach(train)
## Make date variables ##

### year, month & day 
train$claim_date_registered <- ymd(train$claim_date_registered)
train$claim_date_occured <- ymd(train$claim_date_occured)

### only year & month
train$claim_vehicle_date_inuse <- format(lubridate::parse_date_time(train$claim_vehicle_date_inuse, 
                                                                    orders = c("Y/m")), "%Y-%m") 
train$claim_vehicle_date_inuse <- as.Date(as.yearmon(train$claim_vehicle_date_inuse, "%Y-%m"))

train$policy_date_start <- format(lubridate::parse_date_time(train$policy_date_start, 
                                                             orders = c("Y/m")), "%Y-%m") 
train$policy_date_start <- as.Date(as.yearmon(train$policy_date_start, "%Y-%m"))

train$policy_date_next_expiry <- format(lubridate::parse_date_time(train$policy_date_next_expiry, 
                                                                   orders = c("Y/m")), "%Y-%m")
train$policy_date_next_expiry <- as.Date(as.yearmon(train$policy_date_next_expiry, "%Y-%m"))

train$policy_date_last_renewed <- format(lubridate::parse_date_time(train$policy_date_last_renewed, 
                                                                    orders = c("Y/m")), "%Y-%m")
train$policy_date_last_renewed <- as.Date(as.yearmon(train$policy_date_last_renewed, "%Y-%m"))

str(train)


## Separate date columns ## 

### Year, Month & Day

train <- separate(train, claim_date_registered, c("claim_date_registered_Year", 
                                                  "claim_date_registered_Month", 
                                                  "claim_date_registered_Day"), sep = "-")
train <- separate(train, claim_date_occured, c("claim_date_occured_Year", 
                                               "claim_date_occured_Month", 
                                               "claim_date_occured_Day"), sep = "-")

### Year & Month

train <- separate(train, claim_vehicle_date_inuse, 
                  c("claim_vehicle_date_inuse_Year", "claim_vehicle_date_inuse_Month"),
                  sep = "-") 

train <- separate(train, policy_date_start, 
                  c("policy_date_start_Year","policy_date_start_Month"),
                  sep = "-")

train <- separate(train, policy_date_next_expiry, 
                  c("policy_date_next_expiry_Year", "policy_date_next_expiry_Month"),
                  sep = "-")

train <- separate(train, policy_date_last_renewed, 
                  c("policy_date_last_renewed_Year", "policy_date_last_renewed_Month"),
                  sep = "-")

str(train) # hier zie je dat alle data geconverteerd is naar characters, dus deze nog omzetten 
# naar numerieke waarden en we hebben compatibele waarden voor Random Forrest  


## Factorizing all variables & making Numeric ## 
               
train$fraud <- as.factor(train$fraud)                   # does not exist for test data!!                     
train$claim_amount <- as.numeric(train$claim_amount)    # does not exist for test data!!

train$claim_date_registered_Year  <- as.numeric(train$claim_date_registered_Year)    
train$claim_date_registered_Month <- as.numeric(train$claim_date_registered_Month)  
train$claim_date_registered_Day   <- as.numeric(train$claim_date_registered_Day) 
train$claim_date_occured_Year     <- as.numeric(train$claim_date_occured_Year)       
train$claim_date_occured_Month    <- as.numeric(train$claim_date_occured_Month)      
train$claim_date_occured_Day      <- as.numeric(train$claim_date_occured_Day) 

train$claim_time_occured  <- as.numeric(train$claim_time_occured)            
train$claim_postal_code   <- as.numeric(train$claim_postal_code)                 
train$claim_cause         <- as.factor(train$claim_cause)          
train$claim_liable        <- as.factor(train$claim_liable)          
train$claim_num_injured   <- as.numeric(train$claim_num_injured)                
train$claim_num_third_parties <- as.numeric(train$claim_num_third_parties)           
train$claim_num_vehicles  <- as.numeric(train$claim_num_vehicles)                
train$claim_police        <- as.factor(train$claim_police)            
train$claim_alcohol       <- as.factor(train$claim_alcohol)             
train$claim_language      <- as.factor(train$claim_language)

train$claim_vehicle_id        <- as.factor(train$claim_vehicle_id)           
train$claim_vehicle_brand     <- as.factor(train$claim_vehicle_brand)          
train$claim_vehicle_type      <- as.factor(train$claim_vehicle_type)          
train$claim_vehicle_date_inuse_Year <- as.numeric(train$claim_vehicle_date_inuse_Year)    
train$claim_vehicle_date_inuse_Month <- as.numeric(train$claim_vehicle_date_inuse_Month)    
train$claim_vehicle_cyl       <- as.numeric(train$claim_vehicle_cyl)                 
train$claim_vehicle_load      <- as.numeric(train$claim_vehicle_load)               
train$claim_vehicle_fuel_type <- as.factor(train$claim_vehicle_fuel_type)       
train$claim_vehicle_power     <- as.numeric(train$claim_vehicle_power)       

train$policy_holder_id          <- as.factor(train$policy_holder_id)      
train$policy_holder_postal_code <- as.numeric(train$policy_holder_postal_code)        
train$policy_holder_form        <- as.factor(train$policy_holder_form)    
train$policy_holder_year_birth  <- as.numeric(train$policy_holder_year_birth)          
train$policy_holder_country     <- as.factor(train$policy_holder_country )    
train$policy_holder_expert_id   <- as.factor(train$policy_holder_expert_id) 

train$driver_id           <- as.factor(train$driver_id)          
train$driver_postal_code  <- as.numeric(train$driver_postal_code )                
train$driver_form         <- as.factor(train$driver_form)          
train$driver_year_birth   <- as.numeric(train$driver_year_birth )                
train$driver_country      <- as.factor(train$driver_country)          
train$driver_expert_id    <- as.factor(train$driver_expert_id)          
train$driver_injured      <- as.factor(train$driver_injured )          
train$driver_vehicle_id   <- as.factor(train$driver_vehicle_id)          

train$third_party_1_id          <- as.factor(train$third_party_1_id)             
train$third_party_1_postal_code <- as.numeric(train$third_party_1_postal_code)         
train$third_party_1_injured     <- as.factor(train$third_party_1_injured)    
train$third_party_1_vehicle_type <- as.factor(train$third_party_1_vehicle_type)    
train$third_party_1_form        <- as.factor(train$third_party_1_form)    
train$third_party_1_year_birth  <- as.numeric(train$third_party_1_year_birth)      
train$third_party_1_country     <- as.factor(train$third_party_1_country)    
train$third_party_1_vehicle_id  <- as.factor(train$third_party_1_vehicle_id)    
train$third_party_1_expert_id   <- as.factor(train$third_party_1_expert_id) 

train$third_party_2_id          <- as.factor(train$third_party_2_id)             
train$third_party_2_postal_code <- as.numeric(train$third_party_2_postal_code)         
train$third_party_2_injured     <- as.factor(train$third_party_2_injured)    
train$third_party_2_vehicle_type <- as.factor(train$third_party_2_vehicle_type)    
train$third_party_2_form        <- as.factor(train$third_party_2_form)    
train$third_party_2_year_birth  <- as.numeric(train$third_party_2_year_birth)      
train$third_party_2_country     <- as.factor(train$third_party_2_country)    
train$third_party_2_vehicle_id  <- as.factor(train$third_party_2_vehicle_id)    
train$third_party_2_expert_id   <- as.factor(train$third_party_2_expert_id) 

train$third_party_3_id          <- as.factor(train$third_party_3_id)             
train$third_party_3_postal_code <- as.numeric(train$third_party_3_postal_code)         
train$third_party_3_injured     <- as.factor(train$third_party_3_injured)    
train$third_party_3_vehicle_type <- as.factor(train$third_party_3_vehicle_type)    
train$third_party_3_form        <- as.factor(train$third_party_3_form)    
train$third_party_3_year_birth  <- as.numeric(train$third_party_3_year_birth)      
train$third_party_3_country     <- as.factor(train$third_party_3_country)    
train$third_party_3_vehicle_id  <- as.factor(train$third_party_3_vehicle_id)    
train$third_party_3_expert_id   <- as.factor(train$third_party_3_expert_id) 

train$repair_id           <- as.factor(train$repair_id)          
train$repair_postal_code  <- as.numeric(train$repair_postal_code)               
train$repair_form         <- as.factor(train$repair_form )           
train$repair_year_birth   <- as.numeric(train$repair_year_birth)          
train$repair_country      <- as.factor(train$repair_country)          
train$repair_sla          <- as.factor(train$repair_sla)

train$policy_date_start_Year  <- as.numeric(train$policy_date_start_Year)          
train$policy_date_start_Month <- as.numeric(train$policy_date_start_Month)           
train$policy_date_next_expiry_Year  <- as.numeric(train$policy_date_next_expiry_Year)    
train$policy_date_next_expiry_Month <- as.numeric(train$policy_date_next_expiry_Month)    
train$policy_date_last_renewed_Year <- as.numeric(train$policy_date_last_renewed_Year)    
train$policy_date_last_renewed_Month <- as.numeric(train$policy_date_last_renewed_Month)    
train$policy_num_changes      <- as.numeric(train$policy_num_changes)            
train$policy_num_claims       <- as.numeric(train$policy_num_claims)                
train$policy_premium_100      <- as.numeric(train$policy_premium_100)           
train$policy_coverage_1000    <- as.numeric(train$policy_coverage_1000) 

train$policy_coverage_type    <- as.factor(train$policy_coverage_type)
train$policy_coverage_type    <- gsub("#","",as.character(train$policy_coverage_type))
train$policy_coverage_type    <- as.numeric(train$policy_coverage_type)


#### Overbodige kolommen! #### 

# als je de data goed analyseert, dan merk je op dat kolommen "policy_date_last_renewed_Year", 
# "policy_date_last_renewed_Month" helemaal hetzelfde zijn als 

table(train$policy_date_last_renewed_Month == train$policy_date_next_expiry_Month)
table(train$policy_date_last_renewed_Year == train$policy_date_next_expiry_Year)

# Die twee kolommen zijn dus afhankelijk van een andere kolom, dus kan je zonder verlies 
# van algemeenheid verwijderen uit de dataset!

deleteCol <- which(colnames(train) == c("policy_date_last_renewed_Month", 
                                        "policy_date_last_renewed_Year"))

train <- train[,-deleteCol]

#### Overbodige rijen! #### 

A_train <- train
B_train <- train

filter_rijen <- which(as.character(train$driver_vehicle_id) == as.character(train$claim_vehicle_id))

A_train <- train[filter_rijen, ] # contains only values where filter is applied 
B_train <- train[-filter_rijen,]

nrow(A_train) + nrow(B_train) == nrow(train) # correct gesplitst! 

str(train)
detach(train)

save(A_train, file = "A_train.RData")
save(B_train, file = "B_train.RData")
save(train, file = "train.RData")

############
### TEST ###
############

attach(test)

## Make date variables ##

### year, month & day 
test$claim_date_registered <- ymd(test$claim_date_registered)
test$claim_date_occured <- ymd(test$claim_date_occured)

### only year & month
test$claim_vehicle_date_inuse <- format(lubridate::parse_date_time(test$claim_vehicle_date_inuse, 
                                                                    orders = c("Y/m")), "%Y-%m") 
test$claim_vehicle_date_inuse <- as.Date(as.yearmon(test$claim_vehicle_date_inuse, "%Y-%m"))

test$policy_date_start <- format(lubridate::parse_date_time(test$policy_date_start, 
                                                             orders = c("Y/m")), "%Y-%m") 
test$policy_date_start <- as.Date(as.yearmon(test$policy_date_start, "%Y-%m"))

test$policy_date_next_expiry <- format(lubridate::parse_date_time(test$policy_date_next_expiry, 
                                                                   orders = c("Y/m")), "%Y-%m")
test$policy_date_next_expiry <- as.Date(as.yearmon(test$policy_date_next_expiry, "%Y-%m"))

test$policy_date_last_renewed <- format(lubridate::parse_date_time(test$policy_date_last_renewed, 
                                                                    orders = c("Y/m")), "%Y-%m")
test$policy_date_last_renewed <- as.Date(as.yearmon(test$policy_date_last_renewed, "%Y-%m"))

str(test)


## Separate date columns ## 

### Year, Month & Day

test <- separate(test, claim_date_registered, c("claim_date_registered_Year", 
                                                  "claim_date_registered_Month", 
                                                  "claim_date_registered_Day"), sep = "-")
test <- separate(test, claim_date_occured, c("claim_date_occured_Year", 
                                               "claim_date_occured_Month", 
                                               "claim_date_occured_Day"), sep = "-")

### Year & Month

test <- separate(test, claim_vehicle_date_inuse, 
                  c("claim_vehicle_date_inuse_Year", "claim_vehicle_date_inuse_Month"),
                  sep = "-") 

test <- separate(test, policy_date_start, 
                  c("policy_date_start_Year","policy_date_start_Month"),
                  sep = "-")

test <- separate(test, policy_date_next_expiry, 
                  c("policy_date_next_expiry_Year", "policy_date_next_expiry_Month"),
                  sep = "-")

test <- separate(test, policy_date_last_renewed, 
                  c("policy_date_last_renewed_Year", "policy_date_last_renewed_Month"),
                  sep = "-")

str(test) # hier zie je dat alle data geconverteerd is naar characters, dus deze nog omzetten 
# naar numerieke waarden en we hebben compatibele waarden voor Random Forest  


## Factorizing all variables & making Numeric ## 

test$claim_date_registered_Year  <- as.numeric(test$claim_date_registered_Year)    
test$claim_date_registered_Month <- as.numeric(test$claim_date_registered_Month)  
test$claim_date_registered_Day   <- as.numeric(test$claim_date_registered_Day) 
test$claim_date_occured_Year     <- as.numeric(test$claim_date_occured_Year)       
test$claim_date_occured_Month    <- as.numeric(test$claim_date_occured_Month)      
test$claim_date_occured_Day      <- as.numeric(test$claim_date_occured_Day) 

test$claim_time_occured  <- as.numeric(test$claim_time_occured)            
test$claim_postal_code   <- as.numeric(test$claim_postal_code)                 
test$claim_cause         <- as.factor(test$claim_cause)          
test$claim_liable        <- as.factor(test$claim_liable)          
test$claim_num_injured   <- as.numeric(test$claim_num_injured)                
test$claim_num_third_parties <- as.numeric(test$claim_num_third_parties)           
test$claim_num_vehicles  <- as.numeric(test$claim_num_vehicles)                
test$claim_police        <- as.factor(test$claim_police)            
test$claim_alcohol       <- as.factor(test$claim_alcohol)             
test$claim_language      <- as.factor(test$claim_language)

test$claim_vehicle_id        <- as.factor(test$claim_vehicle_id)           
test$claim_vehicle_brand     <- as.factor(test$claim_vehicle_brand)          
test$claim_vehicle_type      <- as.factor(test$claim_vehicle_type)          
test$claim_vehicle_date_inuse_Year <- as.numeric(test$claim_vehicle_date_inuse_Year)    
test$claim_vehicle_date_inuse_Month <- as.numeric(test$claim_vehicle_date_inuse_Month)    
test$claim_vehicle_cyl       <- as.numeric(test$claim_vehicle_cyl)                 
test$claim_vehicle_load      <- as.numeric(test$claim_vehicle_load)               
test$claim_vehicle_fuel_type <- as.factor(test$claim_vehicle_fuel_type)       
test$claim_vehicle_power     <- as.numeric(test$claim_vehicle_power)       

test$policy_holder_id          <- as.factor(test$policy_holder_id)      
test$policy_holder_postal_code <- as.numeric(test$policy_holder_postal_code)        
test$policy_holder_form        <- as.factor(test$policy_holder_form)    
test$policy_holder_year_birth  <- as.numeric(test$policy_holder_year_birth)          
test$policy_holder_country     <- as.factor(test$policy_holder_country )    
test$policy_holder_expert_id   <- as.factor(test$policy_holder_expert_id) 

test$driver_id           <- as.factor(test$driver_id)          
test$driver_postal_code  <- as.numeric(test$driver_postal_code )                
test$driver_form         <- as.factor(test$driver_form)          
test$driver_year_birth   <- as.numeric(test$driver_year_birth )                
test$driver_country      <- as.factor(test$driver_country)          
test$driver_expert_id    <- as.factor(test$driver_expert_id)          
test$driver_injured      <- as.factor(test$driver_injured )          
test$driver_vehicle_id   <- as.factor(test$driver_vehicle_id)          

test$third_party_1_id          <- as.factor(test$third_party_1_id)             
test$third_party_1_postal_code <- as.numeric(test$third_party_1_postal_code)         
test$third_party_1_injured     <- as.factor(test$third_party_1_injured)    
test$third_party_1_vehicle_type <- as.factor(test$third_party_1_vehicle_type)    
test$third_party_1_form        <- as.factor(test$third_party_1_form)    
test$third_party_1_year_birth  <- as.numeric(test$third_party_1_year_birth)      
test$third_party_1_country     <- as.factor(test$third_party_1_country)    
test$third_party_1_vehicle_id  <- as.factor(test$third_party_1_vehicle_id)    
test$third_party_1_expert_id   <- as.factor(test$third_party_1_expert_id) 

test$third_party_2_id          <- as.factor(test$third_party_2_id)             
test$third_party_2_postal_code <- as.numeric(test$third_party_2_postal_code)         
test$third_party_2_injured     <- as.factor(test$third_party_2_injured)    
test$third_party_2_vehicle_type <- as.factor(test$third_party_2_vehicle_type)    
test$third_party_2_form        <- as.factor(test$third_party_2_form)    
test$third_party_2_year_birth  <- as.numeric(test$third_party_2_year_birth)      
test$third_party_2_country     <- as.factor(test$third_party_2_country)    
test$third_party_2_vehicle_id  <- as.factor(test$third_party_2_vehicle_id)    
test$third_party_2_expert_id   <- as.factor(test$third_party_2_expert_id) 

test$third_party_3_id          <- as.factor(test$third_party_3_id)             
test$third_party_3_postal_code <- as.numeric(test$third_party_3_postal_code)         
test$third_party_3_injured     <- as.factor(test$third_party_3_injured)    
test$third_party_3_vehicle_type <- as.factor(test$third_party_3_vehicle_type)    
test$third_party_3_form        <- as.factor(test$third_party_3_form)    
test$third_party_3_year_birth  <- as.numeric(test$third_party_3_year_birth)      
test$third_party_3_country     <- as.factor(test$third_party_3_country)    
test$third_party_3_vehicle_id  <- as.factor(test$third_party_3_vehicle_id)    
test$third_party_3_expert_id   <- as.factor(test$third_party_3_expert_id) 

test$repair_id           <- as.factor(test$repair_id)          
test$repair_postal_code  <- as.numeric(test$repair_postal_code)               
test$repair_form         <- as.factor(test$repair_form )           
test$repair_year_birth   <- as.numeric(test$repair_year_birth)          
test$repair_country      <- as.factor(test$repair_country)          
test$repair_sla          <- as.factor(test$repair_sla)

test$policy_date_start_Year  <- as.numeric(test$policy_date_start_Year)          
test$policy_date_start_Month <- as.numeric(test$policy_date_start_Month)           
test$policy_date_next_expiry_Year  <- as.numeric(test$policy_date_next_expiry_Year)    
test$policy_date_next_expiry_Month <- as.numeric(test$policy_date_next_expiry_Month)    
test$policy_date_last_renewed_Year <- as.numeric(test$policy_date_last_renewed_Year)    
test$policy_date_last_renewed_Month <- as.numeric(test$policy_date_last_renewed_Month)    
test$policy_num_changes      <- as.numeric(test$policy_num_changes)            
test$policy_num_claims       <- as.numeric(test$policy_num_claims)                
test$policy_premium_100      <- as.numeric(test$policy_premium_100)           
test$policy_coverage_1000    <- as.numeric(test$policy_coverage_1000)    

test$policy_coverage_type    <- as.factor(test$policy_coverage_type)
test$policy_coverage_type    <- gsub("#","",as.character(test$policy_coverage_type))
test$policy_coverage_type    <- as.numeric(test$policy_coverage_type)

#### Overbodige kolommen! #### 

# als je de data goed analyseert, dan merk je op dat kolommen "policy_date_last_renewed_Year", 
# "policy_date_last_renewed_Month" helemaal hetzelfde zijn als 

table(test$policy_date_last_renewed_Month == test$policy_date_next_expiry_Month)
table(test$policy_date_last_renewed_Year == test$policy_date_next_expiry_Year)

# Die twee kolommen zijn dus afhankelijk van een andere kolom, dus kan je zonder verlies 
# van algemeenheid verwijderen uit de dataset!

deleteCol <- which(colnames(test) == c("policy_date_last_renewed_Month", 
                                       "policy_date_last_renewed_Year"))

test <- test[,-deleteCol]

filter_rijen <- which(as.character(test$driver_vehicle_id) == as.character(test$claim_vehicle_id))

A_test <- test[filter_rijen, ] # contains only values where filter is applied 
B_test <- test[-filter_rijen,]

nrow(A_test) + nrow(B_test) == nrow(test) # correct gesplitst! 

str(test)
detach(test)

save(A_test, file = "A_test.RData")
save(B_test, file = "B_test.RData")
save(test, file = "test.RData")
```

