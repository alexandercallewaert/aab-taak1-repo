---
title: "Assignment 1 - Report"
author: "Group 29"
date: "4/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown - Introduction

This document can be used to add notes to codes and write down our insights on the output we get.

## Loading data

```{r}
library(tidyverse)     ## install.packages("tidyverse")
library(readr)
library(dplyr)
```

```{r}
## read train data csv. Note the readr:: prefix identifies which package it's in
train <- readr::read_csv2("data/train.csv")
attach(train)
```

## Preprocessing

Let's start by seeing how much missing data there is per feature.  Usually a safe maximum threshold is 5% of the total for large datasets. If missing data for a certain feature or sample is more than 5% then we probably should leave that feature or sample out. We therefore check for features (columns) and samples (rows) where more than 5% of the data is missing using a simple function

```{r}
miss <- function(x){sum(is.na(x))/length(x)*100}
apply(train, 2, miss)
apply(train, 1, miss)

train2 <- train %>% select(!(third_party_2_expert_id:third_party_3_expert_id))

## train_ready <- train2 %>% select(apply(train2, 2, miss) < 20)
## dit is wat ik geprobeerd heb te implementeren, zonder succes - gevolg is deze niet elegante manier van selecteren van features waarvoor percentage missing values kleiner is dan 20%
## twijfel niet om dit te veranderen zodat we gemakkelijk in latere fase treshhold kunnen veranderen om te zien of model dan beter presteert
train_ready <- train2 %>% select(claim_id:claim_date_occured, claim_postal_code:claim_police, claim_language:policy_holder_country, driver_id:driver_form, driver_country, driver_injured, driver_vehicle_id, repair_sla:policy_premium_100, policy_coverage_type)

most_fraudulent <- train_ready %>% 
  filter(fraud == "Y") %>% 
  arrange(desc(claim_amount))
sum(most_fraudulent[1:100, "claim_amount"])
## even kijken wat som van 100 grootste fraudulente claims is om een idee te hebben van de grootte-orde

## nutteloze kolommen weg
train_ready2 <- train_ready %>%
  select(!(claim_id))
  
## instanties verwijderen waarvoor driver_vehicle_id niet overeenkomt met claim_vehicle_id (data quality problemen)
train_ready2 <- train_ready2 %>% 
  filter(driver_vehicle_id ==  claim_vehicle_id)
```

## Exploratory analysis

Understanding features

### Bar plots
```{r}
ggplot(data = train_ready2) +
  geom_bar(mapping = aes(x = fraud))
## Massive class imbalance

ggplot(data = train_ready2) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)
ggplot(data = train_ready2) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 50)
## There seem to be a distribution of claim amounts around 1000 and outliers located above 15 000

ggplot(data = train_ready2) +
  geom_bar(mapping = aes(x = claim_cause))
## Dominant cause of claim registration is traffic_accident
```

### Facets & Frequency polygons

```{r}
ggplot(data = train_ready2) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)+
  facet_wrap(~fraud)

ggplot(data = train_ready2, mapping = aes(x = claim_amount, colour = fraud)) +
  geom_freqpoly(binwidth = 500)
## It seems like there is an equal distribution no matter whether fraud or not
## Trying to zoom in on fraud == "Y" case using most_fraudulent data frame

ggplot(data = most_fraudulent) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)
ggplot(data = most_fraudulent) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 100)
## Generally speaking, same distribituion; but also intermediate cases between 1000 and 15000

ggplot(data = most_fraudulent, mapping = aes(x = claim_amount, colour = claim_cause)) +
  geom_freqpoly(binwidth = 400)
```

### Covariation

```{r}
ggplot(data = most_fraudulent, mapping = aes(x = claim_num_vehicles, y = claim_amount)) + 
  geom_boxplot(mapping = aes(group = cut_width(claim_num_vehicles, 1)))
## This is interesting!
## For fraudulent cases, we see that there is some exceptionally high claim amounts when one vehicle is involved
```

### Correlation

```{r}
library(corrplot)
```

```{r}

```

