---
title: "Assignment 1 - Report"
author: "Group 29"
date: "4/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
```

## R Markdown - Introduction

This document can be used to add notes to codes and write down our insights on the output we get.

## Loading data

```{r}
library(tidyverse)     ## install.packages("tidyverse")
library(readr)
library(dplyr)
```

```{r, message=FALSE, warning=FALSE}
## read train data csv. Note the readr:: prefix identifies which package it's in
train <- readr::read_csv2("data/train.csv")
attach(train)
```

## Preprocessing

Let's start by seeing how much missing data there is per feature. Usually a safe maximum threshold is 5% of the total for large datasets. If missing data for a certain feature or sample is more than 5% then we probably should leave that feature or sample out. We therefore check for features (columns) and samples (rows) where more than 5% of the data is missing using a simple function

```{r}
miss <- function(x){sum(is.na(x))/length(x)*100}
apply(train, 2, miss)
apply(train, 1, miss)

NA_matrix <- as.matrix(apply(train, 2, miss))
variables <- rownames(NA_matrix)
NA_list <- c()
NA_threshold <- 20

for (i in 1:nrow(NA_matrix))
  {
  newElement <- variables[i]
  print(newElement)
  if (NA_matrix[i,1] <= NA_threshold) {NA_list <- c(NA_list, newElement)}
}

## Op deze manier kan je alle namen van variabelen selecteren waarvoor geldt dat de proportie van missing values kleiner of gelijk is aan 20%. Hier kan je de threshold dus bepalen indien je wenst, zie train3. Momenteel komt train3 dus overeen met train_ready indien je threshold op 20% zet. 

train2 <- train %>% select(!(third_party_2_expert_id:third_party_3_expert_id))
train3 <- train %>% select(all_of(NA_list))

## train_ready <- train2 %>% select(apply(train2, 2, miss) < 20)
## dit is wat ik geprobeerd heb te implementeren, zonder succes - gevolg is deze niet elegante manier van selecteren van features waarvoor percentage missing values kleiner is dan 20%
## twijfel niet om dit te veranderen zodat we gemakkelijk in latere fase treshhold kunnen veranderen om te zien of model dan beter presteert -> train3 

train_ready <- train2 %>% select(claim_id:claim_date_occured, claim_postal_code:claim_police, claim_language:policy_holder_country, driver_id:driver_form, driver_country, driver_injured, driver_vehicle_id, repair_sla:policy_premium_100, policy_coverage_type)

most_fraudulent <- train_ready %>% 
  filter(fraud == "Y") %>% 
  arrange(desc(claim_amount))
sum(most_fraudulent[1:100, "claim_amount"])

## even kijken wat som van 100 grootste fraudulente claims is om een idee te hebben van de grootte-orde

## nutteloze kolommen weg
train_ready2 <- train_ready %>%
  select(!(claim_id))
  
## instanties verwijderen waarvoor driver_vehicle_id niet overeenkomt met claim_vehicle_id (data quality problemen), hoe ga je dit aanpakken in de test data? Stel dat dit voorkomt en we toch een voorspelling moeten kunnen geven samen met ID van die instantie... 
train_ready2 <- train_ready2 %>% 
  filter(driver_vehicle_id ==  claim_vehicle_id)
```

Hoe gaat ons model dan deze cases voorspellen in een test set waar dit wel eens het geval is (in 17 van de 29.955 observaties is dit het geval bij test set)? Ik vraag me gewoon af hoe het later getrainde model hier mee zal omgaan... 

## Exploratory analysis

Understanding features

### Bar plots
```{r}
ggplot(data = train_ready2) +
  geom_bar(mapping = aes(x = fraud))
## Massive class imbalance

ggplot(data = train_ready2) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)
ggplot(data = train_ready2) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 50)
## There seem to be a distribution of claim amounts around 1000 and outliers located above 15 000

ggplot(data = train_ready2) +
  geom_bar(mapping = aes(x = claim_cause))
## Dominant cause of claim registration is traffic_accident
```

### Facets & Frequency polygons

```{r}
ggplot(data = train_ready2) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)+
  facet_wrap(~fraud)

ggplot(data = train_ready2, mapping = aes(x = claim_amount, colour = fraud)) +
  geom_freqpoly(binwidth = 500)
## It seems like there is an equal distribution no matter whether fraud or not
## Trying to zoom in on fraud == "Y" case using most_fraudulent data frame

ggplot(data = most_fraudulent) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 500)
ggplot(data = most_fraudulent) +
  geom_histogram(mapping = aes(x = claim_amount), binwidth = 100)
## Generally speaking, same distribituion; but also intermediate cases between 1000 and 15000

ggplot(data = most_fraudulent, mapping = aes(x = claim_amount, colour = claim_cause)) +
  geom_freqpoly(binwidth = 400)
```

### Covariation

```{r}
ggplot(data = most_fraudulent, mapping = aes(x = claim_num_vehicles, y = claim_amount)) + 
  geom_boxplot(mapping = aes(group = cut_width(claim_num_vehicles, 1)))
## This is interesting!
## For fraudulent cases, we see that there is some exceptionally high claim amounts when one vehicle is involved
```

### Correlation

```{r}
library(corrplot)
```

### Factorising the variables 

```{r}
str(train_ready2)
train_ready2$fraud <- as.factor(train_ready2$fraud)

summary()

```

